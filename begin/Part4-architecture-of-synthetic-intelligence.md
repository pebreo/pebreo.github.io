idea: for alignment , we rely on the vast memory and ability of foresight of the machine

## idea - archtecture
- ut must be hiearchical
- it must be probabilistic
- it must have foresight
- implucarions

## ideas


- alignmen
- paperclip problem
- solution: imagination + program to do opposite of human history (plenty of examples)
- 100% explainable + understanbke. upgrade to rcn
- affordBke to all. using rcn, hubdreds times less training data


## Epiphany
 todo: story of roderigo

 todo: section title - probabilities all the way down



What was your epiphany? Current ML uses the old brain way of doing "intelligent" things: stimulus respose. The new brain, or neocrtex, uses imagination (world simulation) to be "intelligent."


## Problem
The way we do ml is expensive & a black box ultimately. What if we could train it w hundreds of times less training data & we know what all the layers of neurons are doing? Down yo Each individual neuron. See Will scaling work?

What if we could get rid of the hidden layers, require hundreds of times worth of data required for training, make if affordable for the entire world, ensure AI safety, and be able to provide dirt cheap AI for the entire world?

The status quo is vacuum tubes, I know the path create the transistor!

The fundamental limitation is hidden layers. You can’t keep doing engineering on black boxes indefinitely, you’ll hit & snag & wont be able to debug it.


## Solution, or probabilites all the way down

Instead of calculus, use a hierarchical form of probabilities in the same branch of mathematics as google page rank. The idea is mainly from Jeff Hawkins, Dileep George & Scott Phoenix. The ideas have already be productized and validated by vicarious (bought out by Google). THey wrote a whitepaper 7 years ago cracking the code of captcha using hundred of times less training data. The key insight is a hierarchical PGM that uses both constant feedback & feedforward in order to handle assumptions AND counterfactual of observations (training data). Furthermore, in Jeff Hawkin's book A Thousand Brains he states the fact that neurons vote - this highly suggests intelligence uses the mathematics of probabilities.

![hiearchical PGM](https://pebreo.github.io/IMG_0144.jpeg)
todo: pgm graph... the brain is repetitive, it couod explain that once "abdtracted" to a certain level like words or ideas, the form doesnt need to change because the princliple is the same: each node all has the same property... tk

Understanding the ingredients to make a synthetic intelligence means knowing it's made of the following essential components: imagination (aka world simulation aka foresight), memory, senses, and optionally qualia. All these things can throttled or scaled; in serial or parallel. The game Ultimate Battle Simulator gave me the inspiration for that notion of throttling or scaling since all those things I just mentioned can be variables in a computer program. Humans now have a solid framework for creating synthetic intelligence that is understandable, explainable, and affordable to all.

What about alignment?

Adding guardrails to synthetic intelligence is brittle because there are too many edges cases. An example of this is that there the many ways people can and do jailbreak current generative ML systems like ChatGPT. Building maximum curiosity, truth seeking , and with foresight (aka imagination) is the best way to align human well-being and synthetic intelligence. Credit Elon Musk for popularizing the notion of maximizing truth seeking & curiosity in order to align human well being to synthetic intelligence.

## video
<iframe width="560" height="315" src="https://www.youtube.com/embed/JNepghYjlc4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

## TLDR
Problem: LLM are expensive & a black box

Solution: RCNs can be human-aligned, completely understandable and explainable, affordabke to all

## Why this would work
- systems in nature can be described in a probabikistic hiearchy
-  Dileep George et al. already built and productized using this approach
- Malice and ill-will not necessarily part of intelligence
- Plenty of training data for human-alignment

## What will happen
- Human-aligned AI, 100% understandable & explainable, affordable to unlock
- Unlock almost unimaginable possibilities from solving humanity's most difficult challenges

## Next chapter
[Part 5: Implication of solved intelligence & consciousness](Part5-implications-of-solved-intelligence.md)

[TOC](https://pebreo.github.io/)



## Architecture
## A Multi-Layered Learner: Software Architecture for Evolving AI

Imagine a machine learning architecture that isn't a rigid monolith, but rather a curious explorer, constantly learning and adapting. This isn't science fiction – it's a potential future where AI development embraces a layered, probabilistic approach, informed by the wisdom of the past and fueled by an insatiable hunger for knowledge. 

The core of this architecture lies in a **hierarchical structure**. Think of it like a pyramid, with the foundation composed of the vast datasets of human history, particularly those related to conflict and anti-social behavior. This layer acts a constant reminder of potential pitfalls.

But the architecture doesn't stop there. Building upon this foundation are layers dedicated to **probabilistic modeling**.  Here, the system delves into the messy, unpredictable world of real-time data, constantly calculating probabilities and refining its understanding. This injects a much-needed dose of flexibility, allowing the AI to navigate the unexpected twists and turns of the real world.

The beauty of this architecture lies in its ability to **simulate**. Borrowing from the phoenix metaphor, the system can create virtual worlds within itself, testing different scenarios and learning from failures without real-world consequences. This foresight allows for continuous improvement and adaptation, ensuring the AI doesn't become a hydra of unintended consequences.

But the most crucial element is the **insatiable curiosity** embedded within the architecture. Just like a wide-ranging explorer, the AI wouldn't be limited to the data sets of human conflict. It would be encouraged to explore diverse fields, from art and literature to philosophy and science. This exposure to a vast range of knowledge would fuel its understanding of the human experience, fostering a more nuanced and ethical approach to decision-making.

This architecture is not a finished product, but rather a framework for a continuously evolving AI. It embraces the "is" of human history, the harsh realities of conflict and anti-social behavior, while striving towards a future where AI can contribute to a more peaceful and prosperous world. It's a testament to the power of diverse learning, a testament to the idea that a well-rounded education, not just laser-focused training, is the key to building truly intelligent and beneficial machines.  

